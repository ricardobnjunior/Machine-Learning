{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import timeit\n",
    "from sklearn.utils.multiclass import unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_of_data = []\n",
    "quantity_of_columns_at_csv = 2622\n",
    "for i in range(quantity_of_columns_at_csv):\n",
    "    names_of_data.append('column_'+str(i))\n",
    "    \n",
    "features_train = pd.read_csv(\"train/features_vgg-f.csv\",sep=';',names=names_of_data)\n",
    "labels_train = pd.read_csv(\"train/classes_vgg-f.csv\", names=['target'])\n",
    "\n",
    "features_test = pd.read_csv(\"test/features_vgg-f.csv\",sep=';',names=names_of_data)\n",
    "labels_test = pd.read_csv(\"test/classes_vgg-f.csv\", names=['target']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = features_train\n",
    "y_train = labels_train\n",
    "\n",
    "x_test = features_test\n",
    "y_test = labels_test\n",
    "\n",
    "idx = np.random.permutation(x_train.index)\n",
    "x_train = x_train.reindex(idx)\n",
    "y_train = y_train.reindex(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ricardo\\ambientes virtuals do python\\tf_gpu_1.13\\virtualcuda\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:921: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.01614722\n",
      "Iteration 2, loss = 1.15592356\n",
      "Iteration 3, loss = 0.93777929\n",
      "Iteration 4, loss = 0.81458736\n",
      "Iteration 5, loss = 0.75230789\n",
      "Iteration 6, loss = 0.68613840\n",
      "Iteration 7, loss = 0.64256244\n",
      "Iteration 8, loss = 0.58929921\n",
      "Iteration 9, loss = 0.55643341\n",
      "Iteration 10, loss = 0.58050616\n",
      "Iteration 11, loss = 0.52248219\n",
      "Iteration 12, loss = 0.48982606\n",
      "Iteration 13, loss = 0.46572565\n",
      "Iteration 14, loss = 0.44701413\n",
      "Iteration 15, loss = 0.42779105\n",
      "Iteration 16, loss = 0.38558461\n",
      "Iteration 17, loss = 0.39597512\n",
      "Iteration 18, loss = 0.41994329\n",
      "Iteration 19, loss = 0.38619104\n",
      "Iteration 20, loss = 0.39113648\n",
      "Iteration 21, loss = 0.36912989\n",
      "Iteration 22, loss = 0.38172157\n",
      "Iteration 23, loss = 0.35889542\n",
      "Iteration 24, loss = 0.33187707\n",
      "Iteration 25, loss = 0.31414587\n",
      "Iteration 26, loss = 0.31256672\n",
      "Iteration 27, loss = 0.28632392\n",
      "Iteration 28, loss = 0.31755054\n",
      "Iteration 29, loss = 0.29065534\n",
      "Iteration 30, loss = 0.33087283\n",
      "Iteration 31, loss = 0.28391321\n",
      "Iteration 32, loss = 0.26698002\n",
      "Iteration 33, loss = 0.26759569\n",
      "Iteration 34, loss = 0.24490868\n",
      "Iteration 35, loss = 0.25287754\n",
      "Iteration 36, loss = 0.24981615\n",
      "Iteration 37, loss = 0.23136394\n",
      "Iteration 38, loss = 0.26492196\n",
      "Iteration 39, loss = 0.25177727\n",
      "Iteration 40, loss = 0.22574786\n",
      "Iteration 41, loss = 0.20444237\n",
      "Iteration 42, loss = 0.24178163\n",
      "Iteration 43, loss = 0.24251931\n",
      "Iteration 44, loss = 0.21581742\n",
      "Iteration 45, loss = 0.22423681\n",
      "Iteration 46, loss = 0.17972829\n",
      "Iteration 47, loss = 0.21069975\n",
      "Iteration 48, loss = 0.20791287\n",
      "Iteration 49, loss = 0.16943734\n",
      "Iteration 50, loss = 0.20170565\n",
      "Iteration 51, loss = 0.19523084\n",
      "Iteration 52, loss = 0.18742033\n",
      "Iteration 53, loss = 0.17198815\n",
      "Iteration 54, loss = 0.20382692\n",
      "Iteration 55, loss = 0.21370677\n",
      "Iteration 56, loss = 0.20298210\n",
      "Iteration 57, loss = 0.14516564\n",
      "Iteration 58, loss = 0.18908036\n",
      "Iteration 59, loss = 0.19154521\n",
      "Iteration 60, loss = 0.14656228\n",
      "Iteration 61, loss = 0.14315677\n",
      "Iteration 62, loss = 0.13797576\n",
      "Iteration 63, loss = 0.12144227\n",
      "Iteration 64, loss = 0.15398696\n",
      "Iteration 65, loss = 0.12330206\n",
      "Iteration 66, loss = 0.11927417\n",
      "Iteration 67, loss = 0.12460890\n",
      "Iteration 68, loss = 0.13790769\n",
      "Iteration 69, loss = 0.11321045\n",
      "Iteration 70, loss = 0.10073348\n",
      "Iteration 71, loss = 0.11742368\n",
      "Iteration 72, loss = 0.12614415\n",
      "Iteration 73, loss = 0.11607604\n",
      "Iteration 74, loss = 0.14723903\n",
      "Iteration 75, loss = 0.12410635\n",
      "Iteration 76, loss = 0.14306469\n",
      "Iteration 77, loss = 0.19812315\n",
      "Iteration 78, loss = 0.09938531\n",
      "Iteration 79, loss = 0.20166859\n",
      "Iteration 80, loss = 0.15652080\n",
      "Iteration 81, loss = 0.12768246\n",
      "Iteration 82, loss = 0.11174579\n",
      "Iteration 83, loss = 0.10779321\n",
      "Iteration 84, loss = 0.09852928\n",
      "Iteration 85, loss = 0.08511504\n",
      "Iteration 86, loss = 0.10147680\n",
      "Iteration 87, loss = 0.20923948\n",
      "Iteration 88, loss = 0.11670173\n",
      "Iteration 89, loss = 0.08684422\n",
      "Iteration 90, loss = 0.09056645\n",
      "Iteration 91, loss = 0.08182480\n",
      "Iteration 92, loss = 0.06975747\n",
      "Iteration 93, loss = 0.07616959\n",
      "Iteration 94, loss = 0.07214057\n",
      "Iteration 95, loss = 0.06180198\n",
      "Iteration 96, loss = 0.09836870\n",
      "Iteration 97, loss = 0.06770611\n",
      "Iteration 98, loss = 0.06472911\n",
      "Iteration 99, loss = 0.06881338\n",
      "Iteration 100, loss = 0.13193522\n",
      "Iteration 101, loss = 0.07022969\n",
      "Iteration 102, loss = 0.07762940\n",
      "Iteration 103, loss = 0.06873261\n",
      "Iteration 104, loss = 0.05337696\n",
      "Iteration 105, loss = 0.04760588\n",
      "Iteration 106, loss = 0.04891036\n",
      "Iteration 107, loss = 0.11439382\n",
      "Iteration 108, loss = 0.11288439\n",
      "Iteration 109, loss = 0.10043111\n",
      "Iteration 110, loss = 0.06749014\n",
      "Iteration 111, loss = 0.09289383\n",
      "Iteration 112, loss = 0.07813880\n",
      "Iteration 113, loss = 0.06052699\n",
      "Iteration 114, loss = 0.04094972\n",
      "Iteration 115, loss = 0.04810043\n",
      "Iteration 116, loss = 0.04869278\n",
      "Iteration 117, loss = 0.08365784\n",
      "Iteration 118, loss = 0.10715888\n",
      "Iteration 119, loss = 0.13541977\n",
      "Iteration 120, loss = 0.23669761\n",
      "Iteration 121, loss = 0.17431087\n",
      "Iteration 122, loss = 0.07522474\n",
      "Iteration 123, loss = 0.05343838\n",
      "Iteration 124, loss = 0.03744222\n",
      "Iteration 125, loss = 0.03445638\n",
      "Iteration 126, loss = 0.04148064\n",
      "Iteration 127, loss = 0.03549270\n",
      "Iteration 128, loss = 0.02812591\n",
      "Iteration 129, loss = 0.05049161\n",
      "Iteration 130, loss = 0.03916829\n",
      "Iteration 131, loss = 0.03542072\n",
      "Iteration 132, loss = 0.08097101\n",
      "Iteration 133, loss = 0.06890761\n",
      "Iteration 134, loss = 0.13246881\n",
      "Iteration 135, loss = 0.10143373\n",
      "Iteration 136, loss = 0.07173238\n",
      "Iteration 137, loss = 0.06758824\n",
      "Iteration 138, loss = 0.04003428\n",
      "Iteration 139, loss = 0.03941625\n",
      "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes=(150,150,150), max_iter=3000, alpha=0.0001,\n",
    "                     solver='adam', verbose=1,  random_state=21,tol=0.000000001)\n",
    "\n",
    "start = timeit.default_timer()\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "stop = timeit.default_timer()\n",
    "accuracy = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  241.39930612672927\n",
      "accuracy:  0.9382978723404255\n"
     ]
    }
   ],
   "source": [
    "print('Time: ', stop - start)\n",
    "print('accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[46,  0,  1,  0,  0,  0,  0,  1,  2,  0],\n",
       "       [ 1, 48,  0,  0,  0,  0,  0,  0,  1,  0],\n",
       "       [ 0,  0, 48,  0,  0,  0,  2,  0,  0,  0],\n",
       "       [ 0,  0,  0, 50,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0, 50,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0, 20,  0,  0,  0,  0],\n",
       "       [ 1,  1,  6,  0,  0,  1, 34,  3,  2,  2],\n",
       "       [ 0,  0,  1,  0,  0,  0,  1, 48,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  1, 49,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  2,  0,  0, 48]], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
